\documentclass[final]{beamer}
\usepackage{algorithmic}
\usepackage{algorithm}
\usepackage[orientation=portrait,
		size=custom, width=55.8, height=91.4,  % poster size 22in=55.88cm 91.44cm=36in
		scale=.99
	]{beamerposter}
\usepackage{listings}
\usepackage[american]{babel}  % language 
\usepackage[utf8]{inputenc}   % std linux encoding

\usetheme{pgassc11poster}            % our poster style
%--set colors for blocks (without frame)---------------------------------------
\setbeamercolor{block title}{fg=ngreen,bg=white}
\setbeamercolor{block body}{fg=black,bg=white}
%--set colors for alerted blocks (with frame)----------------------------------
%--textcolor = fg, backgroundcolor = bg, dblue is the jacobs blue
\setbeamercolor{block alerted title}{fg=white,bg=dblue}%frame color
\setbeamercolor{block alerted body}{fg=black,bg=dblue!10}%body color

%==Titel, date and authors of the poster=======================================
\title{Alternative High Performance Benchmarks in UPC}
\author{Kurt Rudolph, Vivek Kale, Lawrence C. Angrave, William D. Gropp}
\institute{Department of Computer Science, University of Illinois Urbana-Champaign}
\date{\today}
%
%==some usefull qm commands====================================================
%  |x>
\newcommand{\ket}[1]{\left\vert#1\right\rangle}
%  <x|
\newcommand{\bra}[1]{\left\langle#1\right\vert}
%  <x|y>
\newcommand{\braket}[2]{\left< #1 \vphantom{#2}\, \right\vert\left.\!\vphantom{#1} #2 \right>}
%  <x|a|y>
\newcommand{\sandwich}[3]{\left< #1 \vphantom{#2 #3} \right #2 \left|\vphantom{#1 #2} #3 \right>}
%  d/dt
\newcommand{\ddt}{\frac{d}{dt}}
%  D/Dx
\newcommand{\pdd}[1]{\frac{\partial}{\partial#1}}
%  |x|
\newcommand{\abs}[1]{\left\vert#1\right\vert}
%  k_{x}
\newcommand{\kv}[1]{\mathbf{k}_{#1}}




\begin{document}
	\begin{frame}[t]
		\begin{columns}[t] 
			  \begin{column}{0.60\paperwidth} 
%=======================Avstract======================================================================================
				\begin{alertblock}{Abstract}
					Benchmarks for High-Performance clusters generally focus on floating-point intensive calculations.  Few of these address data intensive graph operations, a class of computation rapidly growing in demand. As an alternative to standard floating-point benchmarks, a new benchmark, the Graph 500 has been proposed. The benchmark employs multiple implementations in MPI and MPI-RMA. However, a PGAS implementation has yet to be developed. This project focuses on understanding what capabilities a UPC Graph 500 implementation may offer. Specifically, this is done through: 1. the UPC expressibility for irregular graph operations seen in Graph 500 and 2. performance testing of the efficiency of UPC in the context of irregular parallelism.
				\end{alertblock}
				\vskip2ex
%=======================Linked List Traversal======================================================================================
				\begin{block}{Linked List Traversal}
					As a simple test to measure the efficiency of UPC when performing graph operations, various linked
list structures have been built and a traversal measuring the timing for each is taken.
The nodes are distributed across all threads in the group and colored accordingly as shown in the pictures below.
A single UPC thread traverses the linked list.
				\vskip1ex
				\setbeamercolor{block title}{fg=dgreen,bg=white}
				\setbeamercolor{block body}{fg=black,bg=white}
				\begin{columns}[t,totalwidth=0.60\paperwidth]
					\begin{column}{0.28\paperwidth}
						\setbeamercolor{block alerted title}{fg=white,bg=dgreen}%frame color
						\setbeamercolor{block alerted body}{fg=black,bg=dgreen!10}%body color
						\begin{alertblock}{\small Test Info}
							\begin{itemize}
								\item IBM Power7 with 32 Cores
								\item 32 UPC Threads per run
								\item 32 to 3768 traversal nodes incrementing by 32 nodes per run
								\item Each run repeated 8 times 
							\end{itemize}
						\end{alertblock}
					\end{column}
					\begin{column}{0.28\paperwidth}
						\vskip2ex
						\begin{block}{\small Sequential Thread, Sequential Node\vskip2ex}
							\begin{columns}[t,totalwidth=0.28\paperwidth]
								\begin{column}{0.10\paperwidth}
									\includegraphics[width=0.12\paperwidth]{img/linked_list/seq_proc_seq_node}
								\end{column}
								\begin{column}{0.14\paperwidth}
									\includegraphics[width=0.16\paperwidth]{img/data/seq_proc_seq_node}
								\end{column}
							\end{columns}
						\end{block}
					\end{column}
				\end{columns}
				\vskip2ex
				\begin{columns}[t,totalwidth=0.60\paperwidth]
					\begin{column}{0.28\paperwidth}
						\begin{block}{\small Sequential Node, Sequential Thread\vskip2ex}
							\begin{columns}[t,totalwidth=0.28\paperwidth]
								\begin{column}{0.10\paperwidth}
									\includegraphics[width=0.12\paperwidth]{img/linked_list/seq_node_seq_proc}
								\end{column}
								\begin{column}{0.14\paperwidth}
									\includegraphics[width=0.16\paperwidth]{img/data/seq_node_seq_proc}
								\end{column}
							\end{columns}
						\end{block}
					\end{column}
					\begin{column}{0.28\paperwidth}
						\begin{block}{\small Random Thread, Random Node\vskip2ex}
							\begin{columns}[t,totalwidth=0.28\paperwidth]
								\begin{column}{0.10\paperwidth}
									\includegraphics[width=0.12\paperwidth]{img/linked_list/rand_proc_rand_node}
								\end{column}
								\begin{column}{0.14\paperwidth}
									\includegraphics[width=0.16\paperwidth]{img/data/rand_proc_rand_node}
								\end{column}
							\end{columns}
						\end{block}
					\end{column}
				\end{columns}
				\vskip3ex
				\begin{columns}[t,totalwidth=0.60\paperwidth]
					\begin{column}{0.28\paperwidth}
						\begin{block}{\small Cumulative Results\vskip2ex}
							\includegraphics[width=0.28\paperwidth]{img/data/cumlative_traversal}
						\end{block}
					\end{column}
					\begin{column}{0.28\paperwidth}
						\setbeamercolor{block title}{fg=red,bg=white}
						\setbeamercolor{block body}{fg=black,bg=white}
						\begin{block}{\small Discussion\vskip2ex}
							{\small The results give insight into how UPC graph operations may perform on a given system.  Having a single thread performing the linked list traversal provides a baseline for a fully optimized parallel graph algorithm and allows us to truly test the UPC runtime.

							The jump in timings in the charts at 2600 nodes seems to indicate that the amount of data required to perform the traversal has overflowed the capacity of the CPU's caches.  After that point, much slower access to the next level of cache in the memory hierarchy must be performed in order to complete the traversal.}
						\end{block}
					\end{column}
				\end{columns}
				\end{block}
				\vskip2ex
%=======================Random Access======================================================================================
				\begin{block}{Parallel Random Access}
					When performing graph operations, random access to memory and random thread communications
are very common. This test explores how well a UPC Graph 500 implementation may
handle these operations in parallel. To do so, we implement a dot product employing randomized
access and communication through the RDMA. The vectors are distributed across
all threads in the group and colored accordingly in the picture below.  Accesses are performed simultaneously by all 32 UPC
threads. The test is configured in the same manner as the linked list traversals: IBM Power7 with 32 cores, 32 UPC threads per run, 32 to 3768 memory accesses and array elements per thread per run, and each run is repeated 8 times.   
				\end{block}
				\begin{columns}[t,totalwidth=0.60\paperwidth]
					\begin{column}{0.26\paperwidth}
						{\small \lstinputlisting[language=C, basicstyle=\footnotesize]{ code_sample/upcRandomAccess.c}}
					\end{column}
					\begin{column}{0.10\paperwidth}
						\begin{columns}[t,totalwidth=0.10\paperwidth]
							\begin{column}{0.10\paperwidth}
								\includegraphics[width=0.09\paperwidth]{img/rand_access}
							\end{column}
						\end{columns}
					\end{column}
					\begin{column}{0.24\paperwidth}
						\begin{columns}[t,totalwidth=0.22\paperwidth]
							\begin{column}{0.24\paperwidth}
								\includegraphics[width=0.26\paperwidth]{img/data/random_access}
							\end{column}
						\end{columns}
					\end{column}
				\end{columns}
				\vskip1ex
%=======================Multi Process Linked List Traversal======================================================================================
			\end{column}
			\begin{column}{0.28\paperwidth}
%=======================Discussion=======================================================================================================
				\begin{block}{Graph 500 BFS}
					Currently, the Graph 500 employs multiple implementations using MPI and OpenMP.  
					
					The "Simple" MPI implementation achieves two-sided communication through communicator functions such as  \emph{send} and \emph{receive}. A sample from the Graph 500 BFS MPI Simple implementation is shown below:\vspace{2 mm}
					\lstinputlisting[language=C, basicstyle=\footnotesize]{ code_sample/mpiSimpleSample.c}
					 \vspace{3 mm}
					  The "One Sided" MPI implementation achieves one-sided communication through MPI \emph{windows}, a feature built into MPICH2.  When a process creates an MPI \emph{window}, access to another process's address space is enabled through the variables associated with that window.  A sample from the Graph 500 BFS MPI One Sided implementation is shown below: 
					  \vspace{2 mm}
					  \lstinputlisting[language=C, basicstyle=\footnotesize]{ code_sample/mpiOneSidedSample.c} 
					  \vspace{3 mm}
					  A UPC implementation of the Graph 500 will not require "windows" to achieve one sided communication.  However, memory used in any collective operations needs to be allocated in shared address space.  Note that this may incur some performance loss due to accessing memory via a shared pointer.  MPI collectives from the Graph 500 BFS implemented in UPC take the simpler implementation, as shown below: 
					  \vspace{2 mm}
					  \lstinputlisting[language=C, basicstyle=\footnotesize]{ code_sample/upcOneSidedSample.c} 
				\end{block}
%=======================Conclusion========================================================================================================
				\begin{block}{Summary}
					\begin{itemize}
						\item We have defined performance tests which emulate operations in the Graph 500.  The purpose is to isolate the fundamental task (traversing a linked list) of any graph operation.

						\item We then emulate a fully parallel graph operation in UPC.  The purpose is to identify how well UPC performs massively parallel graph operations with memory randomly distributed to each of the threads.  
			
						\item Finally, we compare the MPI and MPI-RMA implementations of the Graph 500 to a potential UPC implementation.
					\end{itemize}
				\end{block}
%=======================References========================================================================================================
				\begin{block}{\small References\vskip2ex}
					\begin{thebibliography}{7}
						{\tiny
						\bibitem{hpcs_graph_benchmark}
							\emph{Design and Implementation of the HPCS Graph Analysis Benchmark
on Symmetric Multiprocessors}. D.A. Bader, M. Parashar, S. Varadarajan, and V.K. Prasanna, editors, Proc. 12th Int'l. Conf. on High Performance Computing (HiPC 2005), volume 3769 of LNCS, pages 465--476, Goa, India, December 2005. Springer.
							\url{http://www.cse.psu.edu/~madduri/papers/SSCA2-HiPC05.pdf}
						\bibitem{Introduction_To_UPC}
							\emph{Introduction to UPC and Language Specification}
							W. Carlson, J. Draper, D. Culler, K. Yelick, E. Brooks, and K. Warren. CCS-TR-99-157, IDA Center for Computing Sciences, 1999.
						  \url{http://upc.lbl.gov/publications/UPC-TR-Original99.pdf}
						\bibitem{UPC_Language_Spcification}
							\emph{A publication of the UPC Consortium}
							UPC Consortium, the current release of the UPC Language Specification is version 1.2, finalized in June of 2005.
							\url{http://upc.gwu.edu/docs/upc_specs_1.2.pdf}
						\bibitem{MPI}
							\emph{MPI: A Message-Passing Interface Standard} Message Passign Interface Forum, Version 2.2, September 4, 2009 
							\url{http://mpi-forum.org/docs/mpi-2.2/mpi22-report.pdf}
						\bibitem{MPI}
						}
					\end{thebibliography}
				\end{block}
			\end{column}
		\end{columns}
	\end{frame}
\end{document}




%--set custom colors---------------------------------------------------------------
 %  \setbeamercolor{block alerted title}{fg=black,bg=gray!50}%frame color
%   \setbeamercolor{block alerted body}{fg=black,bg=gray!30}%body color
